{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №3\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №1: \n",
    "Вернемся к задаче распознавания рукописных цифр, рассмотренной на первом занятии. Все также будем работать с набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). В данном задании воспользуемся всем датасетом целиком.\n",
    "\n",
    "__Ваша основная задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 92\\%$ на тестовой выборке.__\n",
    "\n",
    "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбуку первого занятия.\n",
    "\n",
    "Настоятельно рекомендуем написать код \"с нуля\", лишь поглядывая на пример, а не просто \"скопировать-вставить\". Это поможет вам в дальнейшем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_mnist_data = MNIST('.', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_mnist_data = MNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f'Image label: {_label}')\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matvey26:**  *Посмотрим на размерность*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mnist_data.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matvey26:** *Теперь посмотрим на то, как устроен отдельный объект*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.6275, 0.9882, 0.9922, 0.9882, 0.9843,\n",
      "        0.3373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000])\n"
     ]
    }
   ],
   "source": [
    "print(_image[0, 0])\n",
    "print(_image[0, 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matvey26:** *Таким образом, данные представляют собой матрицы размера 28 на 28, где каждый пиксель - вещественное число от 0 до 1, где 0 - отсутствие цвета.*\n",
    "\n",
    "**Matvey26:** *На выходе модели - 10 классов. В теории, конечно, можно обучать регрессию, но смысла в этом никакого нет - будем предсказывать вероятности классов*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 92% accuracy.\n",
    "\n",
    "*Комментарий: для этого достаточно линейных слоев и функций активации.*\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model`.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class DigitRecognition(nn.Module):\n",
    "    def __init__(self, img_width, img_height, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        HIDDEN_DIM = 128\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(img_width * img_height, HIDDEN_DIM),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(HIDDEN_DIM, HIDDEN_DIM // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(HIDDEN_DIM // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.img_width * self.img_height)\n",
    "        return self.layers(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            return F.softmax(logits, dim=1)\n",
    "\n",
    "    def fit(self, dataloader, n_epochs=1, lr=0.001):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
    "\n",
    "        self.train()\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images, labels in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.forward(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloader)\n",
    "            epoch_acc = 100 * correct / total\n",
    "\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "        \n",
    "        self.eval()\n",
    "\n",
    "IMG_WIDTH = IMG_HEIGHT = 28\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "model = DigitRecognition(IMG_WIDTH, IMG_HEIGHT, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model is not None, 'Please, use `model` variable to store your model'\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].reshape(-1, 784)\n",
    "    y = random_batch[1]\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model(x)    \n",
    "except Exception as e:\n",
    "    print('Something is wrong with the model')\n",
    "    raise e\n",
    "    \n",
    "    \n",
    "assert y_predicted.shape[-1] == 10, 'Model should predict 10 logits/probas'\n",
    "\n",
    "print('Everything seems fine!')\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настройте параметры модели на обучающей выборке. В качестве примера можете воспользоваться ноутбуком с занятия №1. Также рекомендуем поработать с различными оптимизаторами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 0.3125, Accuracy: 90.78%\n",
      "Epoch [2/2], Loss: 0.1324, Accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_data_loader, n_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in train_data_loader:\n",
    "        y_predicted = model(batch[0].reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.97788\n"
     ]
    }
   ],
   "source": [
    "print(f'Neural network accuracy on train set: {train_acc:3.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader:\n",
    "        y_predicted = model(batch[0].reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.9702\n"
     ]
    }
   ],
   "source": [
    "print(f'Neural network accuracy on test set: {test_acc:3.5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_acc >= 0.92, 'Test accuracy is below 0.92 threshold'\n",
    "assert train_acc >= 0.91, 'Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Загрузите файл `hw03_data_dict.npy` (ссылка есть на странице с заданием) и запустите код ниже для генерации посылки. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/girafe-ai/ml-course/msu_branch/homeworks/hw03_mnist/hw03_data_dict.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_hw03.npy`\n",
      "File saved to `submission_dict_hw03.json`\n",
      "File saved to `submission_dict_hw03.json` (comma-separated format)\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import os\n",
    "\n",
    "assert os.path.exists('hw03_data_dict.npy'), 'Please, download `hw03_data_dict.npy` and place it in the working directory'\n",
    "\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "    \n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx:idx+step].reshape(-1, 784))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "    \n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    return predicted_labels\n",
    "\n",
    "loaded_data_dict = np.load('hw03_data_dict.npy', allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    'train': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['train'])).tolist(),\n",
    "    'test': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['test'])).tolist()\n",
    "}\n",
    "\n",
    "# этот файл проверяющая система отказывается проверять\n",
    "# np.save('submission_dict_hw03.npy', submission_dict, allow_pickle=True)\n",
    "# print('File saved to `submission_dict_hw03.npy`')\n",
    "\n",
    "# Конвертируем списки чисел в строки с запятыми\n",
    "submission_dict_str = {\n",
    "    'train': ','.join(map(str, submission_dict['train'])),\n",
    "    'test': ','.join(map(str, submission_dict['test']))\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('submission_dict_hw03.json', 'w') as f:\n",
    "    json.dump(submission_dict_str, f)\n",
    "\n",
    "print('File saved to `submission_dict_hw03.json` (comma-separated format)')\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
